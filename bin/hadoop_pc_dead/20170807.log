nohup: ignoring input
+ prefix_thang=hdfs://nmg01-taihang-hdfs.dmop.baidu.com:54310
+ prefix_khan=hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310
+ prefix_mulan=hdfs://nmg01-mulan-hdfs.dmop.baidu.com:54310
+ hadoop_khan=/home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/hadoop
+ hadoop_prefix=hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310
+ hadoop_bin=/home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/hadoop
+ [[ 1 == 1 ]]
+ static_date=20170807
+ path_mixer_full=/home/work/shangbai/online/mixer_full
+ hadoop_output=hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/ecom/fcr/liqibo/NA/mixer_full_charge/20170807
+ path_local=/home/work/shangbai/data/20170807/mixer_full_charge
++ list_input 20170807
++ prefix_input=hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dt/udw/release/app/fengchao/shitu/222_223
++ postfix_input='*/part-*'
++ [[ 1 == 1 ]]
++ echo '-input hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dt/udw/release/app/fengchao/shitu/222_223/20170807/*/part-*'
+ hadoop_input='-input hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dt/udw/release/app/fengchao/shitu/222_223/20170807/*/part-*'
+ main_task
+ run_hadoop
+ /home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/hadoop fs -rmr hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/ecom/fcr/liqibo/NA/mixer_full_charge/20170807
rmr: hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/ecom/fcr/liqibo/NA/mixer_full_charge/20170807
+ /home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/hadoop streaming -input 'hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dt/udw/release/app/fengchao/shitu/222_223/20170807/*/part-*' -output hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/ecom/fcr/liqibo/NA/mixer_full_charge/20170807 -mapper 'python27/bin/python2.7 mapper.py' -reducer 'python27/bin/python2.7 reducer.py mixer_full' -file mapper.py -file reducer.py -file /home/work/shangbai/online/mixer_full -cacheArchive /share/python2.7.tar.gz#python27 -jobconf mapred.job.name=liqibo-static -jobconf mapred.job.priority=VERY_HIGH -jobconf mapred.job.queue.name=fcr-adu -jobconf stream.memory.limit=4096 -jobconf mapred.job.map.capacity=3000 -jobconf mapred.map.tasks=2000 -jobconf mapred.job.reduce.capacity=2000 -jobconf mapred.reduce.tasks=1000 -jobconf mapred.job.reduce.memory.mb=5120 -jobconf stream.num.map.output.key.fields=1
17/08/07 14:15:09 WARN streaming.StreamJob: -cacheArchive option is deprecated, please use -archives instead.
17/08/07 14:15:09 WARN streaming.StreamJob: -jobconf option is deprecated, please use -D instead.
packageJobJar: [mapper.py, reducer.py, /home/work/shangbai/online/mixer_full] [/home/work/shangbai/lib/hadoop-client-nmg/hadoop/contrib/streaming/hadoop-2-streaming.jar] /tmp/streamjob1636589496410984183.jar tmpDir=null
17/08/07 14:15:10 INFO mapred.JobClient: class org.apache.hadoop.security.UnixUserGroupInformation
17/08/07 14:15:10 INFO mapred.JobClient: class org.apache.hadoop.security.UnixUserGroupInformation
17/08/07 14:15:11 INFO hdfs.FMSClient: Write 14073756125304900 in pipeline 10.74.218.27:7001, 10.74.64.22:7001, 10.74.66.46:7001, 10.74.124.35:7001, 10.74.124.31:7001, 10.74.194.14:7001, 10.74.209.50:7001, 10.74.186.39:7001, 10.74.185.20:7001, 10.73.80.46:7001
17/08/07 14:15:12 INFO util.NativeCodeLoader: Loaded the native-hadoop library
17/08/07 14:15:12 INFO compress.LzoCodec: Successfully loaded & initialized native-lzo library
17/08/07 14:15:12 INFO compress.LzmaCodec: Successfully loaded & initialized native-lzma library
17/08/07 14:15:12 INFO compress.QuickLzCodec: Successfully loaded & initialized native-quicklz library
17/08/07 14:15:12 INFO mapred.FileInputFormat: getInputPaths: dirs: hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dt/udw/release/app/fengchao/shitu/222_223/20170807/*/part-*
17/08/07 14:15:18 INFO mapred.FileInputFormat: Total input paths to process : 1500
17/08/07 14:15:18 WARN mapred.FileInputFormat: Split size is optimized by default, you can set 'abaci.split.optimize.enable=false' to skip it
17/08/07 14:15:24 INFO hdfs.FMSClient: Write 17169980871511165 in pipeline 10.74.153.28:7001, 10.74.118.34:7001, 10.74.56.19:7001
17/08/07 14:15:25 INFO mapred.JobClient: splits size : 10773
17/08/07 14:15:25 INFO hdfs.FMSClient: Write 1688857152089252 in pipeline 10.74.92.42:7001, 10.74.103.37:7001, 10.74.143.37:7001
17/08/07 14:15:25 INFO split.SplitUtils: create hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/dc/deva/system/mapred/job_20170705161142_1594609/split.done
17/08/07 14:15:26 INFO hdfs.FMSClient: Write 9851631476875919 in pipeline 10.74.158.30:7001, 10.74.130.41:7001, 10.74.94.41:7001
17/08/07 14:15:26 INFO mapred.JobClient: Running job: job_20170705161142_1594609
17/08/07 14:15:26 INFO mapred.JobClient: To kill this job, run:
17/08/07 14:15:26 INFO mapred.JobClient: /home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/../bin/hadoop job -Dmapred.job.tracker=nmg01-khan-abaci.dmop.baidu.com:54311 -kill job_20170705161142_1594609
17/08/07 14:15:26 INFO mapred.JobClient: Tracking URL: http://nmg01-khan-mapred01.nmg01.baidu.com:8030/jobproxy.jsp?jobid=job_20170705161142_1594609
17/08/07 14:15:47 INFO mapred.JobClient: Total split num: 10773
17/08/07 14:15:47 INFO mapred.JobClient: Total split size: 3159836 (bytes)
17/08/07 14:15:47 INFO mapred.JobClient: Total split time: 13414 (ms)
17/08/07 14:15:48 INFO mapred.JobClient:  map 0% reduce 0%
17/08/07 14:17:10 INFO mapred.JobClient: Updating completed job! Ignoring ...
17/08/07 14:17:10 INFO mapred.JobClient: Updating completed job! Ignoring ...
17/08/07 14:17:10 ERROR mapred.JobClient: Job not Successful!
Streaming Job Failed!
+ [[ -f /home/work/shangbai/data/20170807/mixer_full_charge ]]
+ /home/work/shangbai/lib/hadoop-client-nmg/hadoop/bin/hadoop fs -getmerge hdfs://nmg01-khan-hdfs.dmop.baidu.com:54310/app/ecom/fcr/liqibo/NA/mixer_full_charge/20170807 /home/work/shangbai/data/20170807/mixer_full_charge
